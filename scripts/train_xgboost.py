# XGBoost Baseline for Sepsis Prediction (6h Horizon)
#
# This model mirrors the logistic regression baseline, with the following additions:
#   1. Explicit removal of leaking / invalid features
#   2. All column operations performed BEFORE imputation
#   3. XGBoost allowed to perform internal feature selection
#
# This model is used strictly as a comparative baseline against logistic regression.
# It is not proposed as a production-ready model.
#
# The input file (ml_export_6h.csv) is generated by the SQL pipeline in /sql/
# and is NOT included in this repository due to MIMIC-IV data governance restrictions.

# Imports

from pathlib import Path
import json

import pandas as pd
import numpy as np

from sklearn.impute import SimpleImputer
from sklearn.metrics import roc_auc_score, average_precision_score

import xgboost as xgb

# Paths

try:
    BASE_DIR = Path(__file__).resolve().parents[1]
except NameError:
    BASE_DIR = Path.cwd().resolve()

DATA_FILE = BASE_DIR / "ml_export_6h.csv"
RESULTS_DIR = BASE_DIR / "results"

RESULTS_DIR.mkdir(parents=True, exist_ok=True)

PRED_FILE = RESULTS_DIR / "predictions_xgb.csv"
METRICS_FILE = RESULTS_DIR / "metrics_xgb.json"

# Load data

df = pd.read_csv(DATA_FILE)

train = df[df.data_split == "train"].copy()
val   = df[df.data_split == "val"].copy()
test  = df[df.data_split == "test"].copy()

print("Rows:")
print(df.data_split.value_counts())

# Separate features and label

TARGET = "label_sepsis_6h"
DROP_COLS = ["stay_id", "data_split", TARGET]

X_train = train.drop(columns=DROP_COLS)
y_train = train[TARGET]

X_val = val.drop(columns=DROP_COLS)
y_val = val[TARGET]

X_test = test.drop(columns=DROP_COLS)
y_test = test[TARGET]

print("Feature matrix shape (before drops):", X_train.shape)

# Convert PostgreSQL booleans ('t'/'f') to numeric

def tf_to_numeric(df: pd.DataFrame) -> pd.DataFrame:
    for col in df.columns:
        if df[col].dtype == object:
            unique_vals = set(df[col].dropna().unique())
            if unique_vals.issubset({"t", "f"}):
                df[col] = df[col].map({"t": 1, "f": 0})
    return df

X_train = tf_to_numeric(X_train)
X_val   = tf_to_numeric(X_val)
X_test  = tf_to_numeric(X_test)

# Drop leaking / invalid features

LEAKY_FEATURES = [
    "sepsis_onset_hour",    # direct label leakage
    "sofa_total_24h",       # future-looking aggregate
    "sofa_coagulation",     # future-looking component
    "sofa_cardiovascular",  # future-looking component
]

X_train = X_train.drop(columns=LEAKY_FEATURES, errors="ignore")
X_val   = X_val.drop(columns=LEAKY_FEATURES, errors="ignore")
X_test  = X_test.drop(columns=LEAKY_FEATURES, errors="ignore")

print("Feature matrix shape (after drops):", X_train.shape)

# Missing value imputation (median)

imputer = SimpleImputer(strategy="median")

X_train = imputer.fit_transform(X_train)
X_val   = imputer.transform(X_val)
X_test  = imputer.transform(X_test)

# Model definition

model = xgb.XGBClassifier(
    n_estimators=300,
    max_depth=5,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    objective="binary:logistic",
    eval_metric="aucpr",
    tree_method="hist",
    n_jobs=-1,
    random_state=42,
)

# Training

model.fit(
    X_train,
    y_train,
    eval_set=[(X_val, y_val)],
    verbose=False,
)

# Evaluation

def evaluate_split(X, y):
    probs = model.predict_proba(X)[:, 1]
    return {
        "auroc": roc_auc_score(y, probs),
        "auprc": average_precision_score(y, probs),
        "n": int(len(y)),
    }, probs


metrics = {}

metrics["train"], _ = evaluate_split(X_train, y_train)
metrics["val"],   _ = evaluate_split(X_val,   y_val)
metrics["test"],  probs_test = evaluate_split(X_test,  y_test)

metrics["prevalence"] = float(y_test.mean())

print("\nXGBoost performance (leak-free)")
print("-------------------------------")
for split in ["train", "val", "test"]:
    m = metrics[split]
    print(f"{split:5s} | AUROC: {m['auroc']:.3f} | AUPRC: {m['auprc']:.3f}")

# Save outputs

pd.DataFrame({
    "y_true": y_test,
    "y_pred": probs_test,
}).to_csv(PRED_FILE, index=False)

with open(METRICS_FILE, "w") as f:
    json.dump(metrics, f, indent=2)
